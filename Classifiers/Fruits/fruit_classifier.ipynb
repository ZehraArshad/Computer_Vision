{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1363d4c5",
   "metadata": {},
   "source": [
    "### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d55edb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# opencv\n",
    "import cv2\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Flatten, GlobalAveragePooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, EfficientNetB0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6ae993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Common classes in all sets: 15\n",
      "\n",
      " Classes only in train: set()\n",
      " Classes only in val: set()\n",
      " Classes only in test: set()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define paths\n",
    "train = r\"D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\train\"\n",
    "val = r\"D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\val\"\n",
    "test = r\"D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\test\"\n",
    "\n",
    "# Get class names\n",
    "train_classes = set(os.listdir(train))\n",
    "val_classes = set(os.listdir(val))\n",
    "test_classes = set(os.listdir(test))\n",
    "\n",
    "# Find common and mismatched class names\n",
    "common_classes = train_classes & val_classes & test_classes\n",
    "train_only = train_classes - common_classes\n",
    "val_only = val_classes - common_classes\n",
    "test_only = test_classes - common_classes\n",
    "\n",
    "# Print summary\n",
    "print(f\" Common classes in all sets: {len(common_classes)}\\n\")\n",
    "print(f\" Classes only in train: {train_only}\")\n",
    "print(f\" Classes only in val: {val_only}\")\n",
    "print(f\" Classes only in test: {test_only}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbcda4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: Apple 5 → apple\n",
      "Renamed: Avocado Black 1 → avocado black\n",
      "Renamed: Beans 1 → beans\n",
      "Renamed: Blackberrie 1 → blackberrie\n",
      "Renamed: Cabbage red 1 → cabbage red\n",
      "Renamed: Cactus fruit green 1 → cactus fruit green\n",
      "Renamed: Caju seed 1 → caju seed\n",
      "Renamed: carrot_1 → carrot\n",
      "Renamed: Cherimoya 1 → cherimoya\n",
      "Renamed: Cherry 3 → cherry\n",
      "Renamed: Cucumber 4 → cucumber\n",
      "Renamed: eggplant_long_1 → eggplant_long\n",
      "Renamed: Gooseberry 1 → gooseberry\n",
      "Renamed: Nut 1 → nut\n",
      "Renamed: pear_1 → pear\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "folder = r\"D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\train\"\n",
    "\n",
    "for class_folder in os.listdir(folder):\n",
    "    old_path = os.path.join(folder, class_folder)\n",
    "    \n",
    "    # Remove trailing underscores and numbers (e.g., 'carrot_1' → 'carrot')\n",
    "    new_name = re.sub(r'[_\\s]?\\d+$', '', class_folder.lower())\n",
    "    new_path = os.path.join(folder, new_name)\n",
    "\n",
    "    if old_path == new_path:\n",
    "        continue  # Already correct\n",
    "\n",
    "    if not os.path.exists(new_path):\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed: {class_folder} → {new_name}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Skipped (already exists): {new_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "009b0472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple: 294 images\n",
      "avocado black: 468 images\n",
      "beans: 155 images\n",
      "blackberrie: 300 images\n",
      "cabbage red: 99 images\n",
      "cactus fruit green: 465 images\n",
      "caju seed: 151 images\n",
      "carrot: 101 images\n",
      "cherimoya: 648 images\n",
      "cherry: 465 images\n",
      "cucumber: 152 images\n",
      "eggplant_long: 160 images\n",
      "gooseberry: 310 images\n",
      "nut: 161 images\n",
      "pear: 326 images\n",
      "\n",
      "Total images in 'D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\train': 4255\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_dir = r'D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\train'  # change to val or test if needed\n",
    "\n",
    "total_images = 0\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        image_count = len([\n",
    "            img for img in os.listdir(class_path)\n",
    "            if os.path.isfile(os.path.join(class_path, img))\n",
    "        ])\n",
    "        print(f\"{class_name}: {image_count} images\")\n",
    "        total_images += image_count\n",
    "\n",
    "print(f\"\\nTotal images in '{dataset_dir}': {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07c9ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple: 146 images\n",
      "avocado black: 234 images\n",
      "beans: 78 images\n",
      "blackberrie: 150 images\n",
      "cabbage red: 50 images\n",
      "cactus fruit green: 234 images\n",
      "caju seed: 75 images\n",
      "carrot: 50 images\n",
      "cherimoya: 324 images\n",
      "cherry: 234 images\n",
      "cucumber: 76 images\n",
      "eggplant_long: 80 images\n",
      "gooseberry: 156 images\n",
      "nut: 80 images\n",
      "pear: 162 images\n",
      "\n",
      "Total images in 'D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\val': 2129\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_dir = r'D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\val'  # change to val or test if needed\n",
    "\n",
    "total_images = 0\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        image_count = len([\n",
    "            img for img in os.listdir(class_path)\n",
    "            if os.path.isfile(os.path.join(class_path, img))\n",
    "        ])\n",
    "        print(f\"{class_name}: {image_count} images\")\n",
    "        total_images += image_count\n",
    "\n",
    "print(f\"\\nTotal images in '{dataset_dir}': {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98b13328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple: 146 images\n",
      "avocado: 231 images\n",
      "beans: 77 images\n",
      "blackberrie: 150 images\n",
      "cabbage: 49 images\n",
      "cactus: 231 images\n",
      "caju: 75 images\n",
      "carrot: 50 images\n",
      "cherimoya: 320 images\n",
      "cherry: 231 images\n",
      "cucumber: 76 images\n",
      "eggplant_long: 80 images\n",
      "gooseberry: 154 images\n",
      "nut: 80 images\n",
      "pear: 162 images\n",
      "\n",
      "Total images in 'D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\test': 2112\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_dir = r'D:\\fruits\\fruits-360_original-size\\fruits-360-original-size\\test'  # change to val or test if needed\n",
    "\n",
    "total_images = 0\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        image_count = len([\n",
    "            img for img in os.listdir(class_path)\n",
    "            if os.path.isfile(os.path.join(class_path, img))\n",
    "        ])\n",
    "        print(f\"{class_name}: {image_count} images\")\n",
    "        total_images += image_count\n",
    "\n",
    "print(f\"\\nTotal images in '{dataset_dir}': {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d90d372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_gen= ImageDataGenerator(\n",
    "                              # normalize\n",
    "                              rescale=1/255, \n",
    "                              rotation_range=30, \n",
    "                              width_shift_range=0.1, \n",
    "                              shear_range=0.9, \n",
    "                            zoom_range=0.2, \n",
    "                              horizontal_flip=True, \n",
    "                              height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a27456a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4255 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_img = train_image_gen.flow_from_directory(train,\n",
    "                                              target_size = (224,224)\n",
    "                                              , batch_size=16,\n",
    "                                              class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69dd2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_gen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ad80a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2129 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "val_image = val_image_gen.flow_from_directory(val,\n",
    "                                              target_size = (224,224)\n",
    "                                              , batch_size=16,\n",
    "                                              class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a7635b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2112 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_img = test_image_gen.flow_from_directory(\n",
    "    test,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode='sparse',\n",
    "        shuffle=False  # Important for consistent evaluation, especially with confusion matrix etc.\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "325c9c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "num_classes = len(os.listdir(train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5236a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd56103a",
   "metadata": {},
   "source": [
    "Training while freezing base layers, no early stopping and few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37770274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 1s/step - accuracy: 0.1049 - loss: 2.9179 - val_accuracy: 0.1522 - val_loss: 2.4729\n",
      "Epoch 2/2\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 1s/step - accuracy: 0.1491 - loss: 2.6059 - val_accuracy: 0.2184 - val_loss: 2.4278\n"
     ]
    }
   ],
   "source": [
    "base = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "resnet_model = build_model(base)\n",
    "\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "resnet_model.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_resnet = resnet_model.fit(train_img, validation_data=val_image, epochs=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7daa0a0",
   "metadata": {},
   "source": [
    "Unfreezing base layers, early stopping and more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 1s/step - accuracy: 0.0831 - loss: 3.0281 - val_accuracy: 0.1522 - val_loss: 2.4874 - learning_rate: 1.0000e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957ms/step - accuracy: 0.1387 - loss: 2.5935"
     ]
    }
   ],
   "source": [
    "# Freeze all base layers first\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.2, verbose=1)\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False\n",
    "\n",
    "resnet_model_2 = build_model(base_model)\n",
    "resnet_model_2.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Phase 1: Train only top layers\n",
    "resnet_model_2.fit(train_img, validation_data=val_image, epochs=5, callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "# 2. Unfreeze last 30 layers\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "resnet_model_2.compile(optimizer=Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Phase 2: Fine-tune\n",
    "resnet_model_2.fit(train_img, validation_data=val_image, epochs=5, callbacks=[early_stop, reduce_lr])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_for_eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
